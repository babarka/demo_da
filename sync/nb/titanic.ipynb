{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Spark-on-YARN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.3.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.10 (default, Sep 15 2015 14:50:01)\n",
      "SparkContext available as sc, HiveContext available as sqlCtx.\n"
     ]
    }
   ],
   "source": [
    "execfile('../init/spark_init.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Train Data and set schema:\n",
    "We'll read the csv files directly from hdfs and preview what each row looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked',\n",
       " u'1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S',\n",
       " u'2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_train = sc.textFile('/user/cloudera/train.csv')\n",
    "dat_train.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Data Variable Description:\n",
    "We have all the sufficent information to try to predict if someone survives the titanic sinking...\n",
    "\n",
    "| Field     | Description                                                            |\n",
    "|:--------- | ---------------------------------------------------------------------- |\n",
    "| obs       | Observation                                                            |\n",
    "| survival  | Survival (0 = No; 1 = Yes)                                             |\n",
    "| pclass    | Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)                            |\n",
    "| name      | Name                                                                   |\n",
    "| sex       | Sex                                                                    |\n",
    "| age       | Age                                                                    |\n",
    "| sibsp     | Number of Siblings/Spouses Aboard                                      |\n",
    "| parch     | Number of Parents/Children Aboard                                      |\n",
    "| ticket    | Ticket Number                                                          |\n",
    "| fare      | Passenger Fare                                                         |\n",
    "| cabin     | Cabin                                                                  |\n",
    "| embarked  | Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)   |\n",
    "\n",
    "However, we will need to make the following changes to the rdd so that it can be read as LabelPoint form into a model:\n",
    "\n",
    "**survival**: Set the survival field to integer and set as label.\n",
    "\n",
    "**pclass**: Set the pclass field to integer and set as categorical feature.\n",
    "\n",
    "**sex**: Set the sex field to integer and set as categorical feature.\n",
    "\n",
    "**age**: Set the age field to float and set as feature. NOTE: missing ages are set to 30.\n",
    "\n",
    "**sibsp**: Set the sibsp field to float and set as feature.\n",
    "\n",
    "**parch**: Set the parch field to float and set as feature.\n",
    "\n",
    "**cabin**: Map the cabin field to categorical feature.\n",
    "\n",
    "**embark**: Map the embark field to categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "def titanic_lp(x):\n",
    "    fld = x.split(',')\n",
    "    survival = int(fld[1])\n",
    "    pclass   = int(fld[2])-1\n",
    "    sexes    = {'female': 0, 'male': 1}\n",
    "    sex      = sexes[fld[5]]\n",
    "    age      = 30.0 if fld[6]=='' else float(fld[6])\n",
    "    sibsp    = float(fld[7])\n",
    "    parch    = float(fld[8])\n",
    "    cabins   = {'A':1,'B':2,'C':3,'D':4}\n",
    "    cabin    = 0 if ((fld[11]+'X')[0] not in cabins) else cabins[(fld[11]+'X')[0]]\n",
    "    embarks  = {'C':1,'Q':2,'S':3}\n",
    "    embark   = 0 if (fld[12] not in embarks) else embarks[fld[12]]\n",
    "    label    = survival\n",
    "    feats    =[pclass,sex,age,sibsp,parch,cabin,embark]\n",
    "    return LabeledPoint(label, feats)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have categorical variables, we'll need to define the Categorical Feature Info (cfi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_cfi = {0:3,1:2,5:5,6:4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's map the train data into LabeledPoint form and have a look at the top 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [2.0,1.0,22.0,1.0,0.0,0.0,3.0]),\n",
       " LabeledPoint(1.0, [0.0,0.0,38.0,1.0,0.0,3.0,1.0]),\n",
       " LabeledPoint(1.0, [2.0,0.0,26.0,0.0,0.0,0.0,3.0])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_train = dat_train.filter(lambda x: x[0]!='P').map(titanic_lp).cache()\n",
    "lp_train.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model using Training Data and cfi\n",
    "We'll train our model. The model form isn't readily available to be plot as a tree diagram. However, our is still small enough that it can be read directly from the DebugString."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel classifier of depth 3 with 15 nodes\n",
      "  If (feature 1 in {1.0})\n",
      "   If (feature 0 in {0.0})\n",
      "    If (feature 2 <= 28.0)\n",
      "     Predict: 1.0\n",
      "    Else (feature 2 > 28.0)\n",
      "     Predict: 0.0\n",
      "   Else (feature 0 not in {0.0})\n",
      "    If (feature 2 <= 20.0)\n",
      "     Predict: 0.0\n",
      "    Else (feature 2 > 20.0)\n",
      "     Predict: 0.0\n",
      "  Else (feature 1 not in {1.0})\n",
      "   If (feature 0 in {2.0})\n",
      "    If (feature 6 in {3.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 6 not in {3.0})\n",
      "     Predict: 1.0\n",
      "   Else (feature 0 not in {2.0})\n",
      "    If (feature 6 in {0.0,1.0,2.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 6 not in {0.0,1.0,2.0})\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "model = DecisionTree.trainClassifier(data=lp_train, numClasses=2, categoricalFeaturesInfo=titanic_cfi,\n",
    "                                     impurity=\"gini\", maxDepth=3, maxBins=5, minInfoGain=0.0)\n",
    "\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Model Training Data Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148148148148149"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = lp_train.map(lambda lp: lp.label).zip(model.predict(lp_train.map(lambda lp: lp.features)))\n",
    "train_err = te.filter(lambda (v, p): v != p).count() / float(te.count())\n",
    "1-train_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Survival with Test Data\n",
    "Now we can predict the survivors of the test data using the omdel we fit from out training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, u'892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q'),\n",
       " (0.0, u'893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S'),\n",
       " (0.0, u'894,2,\"Myles, Mr. Thomas Francis\",male,62,0,0,240276,9.6875,,Q'),\n",
       " (0.0, u'895,3,\"Wirz, Mr. Albert\",male,27,0,0,315154,8.6625,,S'),\n",
       " (0.0,\n",
       "  u'896,3,\"Hirvonen, Mrs. Alexander (Helga E Lindqvist)\",female,22,1,1,3101298,12.2875,,S'),\n",
       " (0.0, u'897,3,\"Svensson, Mr. Johan Cervin\",male,14,0,0,7538,9.225,,S'),\n",
       " (1.0, u'898,3,\"Connolly, Miss. Kate\",female,30,0,0,330972,7.6292,,Q'),\n",
       " (0.0, u'899,2,\"Caldwell, Mr. Albert Francis\",male,26,1,1,248738,29,,S'),\n",
       " (1.0,\n",
       "  u'900,3,\"Abrahim, Mrs. Joseph (Sophie Halaut Easu)\",female,18,0,0,2657,7.2292,,C'),\n",
       " (0.0, u'901,3,\"Davies, Mr. John Samuel\",male,21,2,0,A/4 48871,24.15,,S')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_test = sc.textFile('/user/cloudera/test.csv').filter(lambda x: x[0]!='P')\n",
    "lp_test_feature = dat_test.map(lambda x: titanic_lp(x.split(',')[0] + ',0,'  + ','.join(x.split(',')[1:])).features)\n",
    "test_predict = model.predict(lp_test_feature).zip(dat_test)\n",
    "test_predict.take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
